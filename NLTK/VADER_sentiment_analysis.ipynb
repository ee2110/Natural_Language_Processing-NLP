{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VADER-sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VKFmV4Cb0Am"
      },
      "source": [
        "**VADER** (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrP85EPGbzVm",
        "outputId": "332ae0df-5e33-4b62-dbb6-38dddb4f1ded"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r17wUezkfDCP",
        "outputId": "3d375bde-78a7-4a46-b3e5-b8cfa6b30180"
      },
      "source": [
        "data = pd.read_csv('combined_data.csv')\n",
        "sentences = data['text'].tolist()\n",
        "labels = data['sentiment'].tolist()\n",
        "sentences[:10]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['So there is no way for me to plug it in here in the US unless I go by a converter.',\n",
              " 'Good case Excellent value.',\n",
              " 'Great for the jawbone.',\n",
              " 'Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!',\n",
              " 'The mic is great.',\n",
              " 'I have to jiggle the plug to get it to line up right to get decent volume.',\n",
              " 'If you have several dozen or several hundred contacts then imagine the fun of sending each of them one by one.',\n",
              " 'If you are Razr owner...you must have this!',\n",
              " 'Needless to say I wasted my money.',\n",
              " 'What a waste of money and time!.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ0iRfWPge-t"
      },
      "source": [
        "test = sentences[0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdxfNP2YgP2l",
        "outputId": "59bbb411-d081-4afd-d0e2-7d24b1917988"
      },
      "source": [
        "vader_sid = SentimentIntensityAnalyzer()\n",
        "sentiment_dict = vader_sid.polarity_scores(test)\n",
        "sentiment_dict"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': -0.3535, 'neg': 0.12, 'neu': 0.88, 'pos': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AEa50ADrR2J"
      },
      "source": [
        "The Compound score is a metric that calculates the sum of all the lexicon ratings which have been **normalized between -1(most extreme negative) and +1 (most extreme positive)**.\n",
        "\n",
        "*   positive sentiment : (compound score >= 0.05) \n",
        "*   neutral sentiment : (compound score > -0.05) and (compound score < 0.05) \n",
        "*   negative sentiment : (compound score <= -0.05)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPC70kTmgMOV"
      },
      "source": [
        "def sentiment_polarity(sentence):\n",
        "    vader_sid = SentimentIntensityAnalyzer()\n",
        "    sentiment_dict = vader_sid.polarity_scores(test)\n",
        "    if sentiment_dict['compound'] >= 0.05 :\n",
        "        sentiment = \"Positive\"\n",
        "    elif sentiment_dict['compound'] <= - 0.05 :\n",
        "        sentiment = \"Negative\"\n",
        "    else :\n",
        "        sentiment = \"Neutral\"\n",
        "\n",
        "    return sentiment_dict['compound'], sentiment_dict['neg'], sentiment_dict['neu'], sentiment_dict['pos'], sentiment\n",
        "\n",
        "def sentiment_label(sentence):\n",
        "    vader_sid = SentimentIntensityAnalyzer()\n",
        "    sentiment_dict = vader_sid.polarity_scores(test)\n",
        "    if sentiment_dict['compound'] >= 0.05 :\n",
        "        sentiment = \"Positive\"\n",
        "    elif sentiment_dict['compound'] <= - 0.05 :\n",
        "        sentiment = \"Negative\"\n",
        "\n",
        "    return "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "DxAUdHy-fvFM",
        "outputId": "c6a5607c-eea1-4514-8853-28be02595777"
      },
      "source": [
        "df_result = pd.DataFrame(\n",
        "    {'text': sentences,\n",
        "     'actual_label': labels\n",
        "    })\n",
        "df_result"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>actual_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988</th>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990</th>\n",
              "      <td>The whole experience was underwhelming and I t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>Then as if I hadn't wasted enough of my life t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1992 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  actual_label\n",
              "0     So there is no way for me to plug it in here i...             0\n",
              "1                            Good case Excellent value.             1\n",
              "2                                Great for the jawbone.             1\n",
              "3     Tied to charger for conversations lasting more...             0\n",
              "4                                     The mic is great.             1\n",
              "...                                                 ...           ...\n",
              "1987  I think food should have flavor and texture an...             0\n",
              "1988                           Appetite instantly gone.             0\n",
              "1989  Overall I was not impressed and would not go b...             0\n",
              "1990  The whole experience was underwhelming and I t...             0\n",
              "1991  Then as if I hadn't wasted enough of my life t...             0\n",
              "\n",
              "[1992 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9bC14swJDmp"
      },
      "source": [
        "df_result[['neg', 'neu', 'pos', 'compound']] = df_result['text'].apply(sentiment_polarity).apply(pd.Series)\n",
        "df_result['pred_label'] = df_result.apply(lambda row : add(row['A'],row['B'], row['C']), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXy8NvCfipN"
      },
      "source": [
        "\n",
        "df_character_sentiment.reset_index(inplace=True, drop=True)\n",
        "df_character_sentiment[['neg', 'neu', 'pos', 'compound']] = df_character_sentiment['character_words'].apply(sid.polarity_scores).apply(pd.Series)\n",
        "df_character_sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pMgo5Ekc8MN"
      },
      "source": [
        "# reading and wragling data\n",
        "df_avatar = pd.read_csv('avatar.csv', engine='python')\n",
        "df_avatar_lines = df_avatar.groupby('character').count()\n",
        "df_avatar_lines = df_avatar_lines.sort_values(by=['character_words'], ascending=False)[:10]\n",
        "top_character_names = df_avatar_lines.index.values\n",
        "\n",
        "# filtering out non-top characters\n",
        "df_character_sentiment = df_avatar[df_avatar['character'].isin(top_character_names)]\n",
        "df_character_sentiment = df_character_sentiment[['character', 'character_words']]\n",
        "\n",
        "# calculating sentiment score\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "df_character_sentiment.reset_index(inplace=True, drop=True)\n",
        "df_character_sentiment[['neg', 'neu', 'pos', 'compound']] = df_character_sentiment['character_words'].apply(sid.polarity_scores).apply(pd.Series)\n",
        "df_character_sentiment"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}