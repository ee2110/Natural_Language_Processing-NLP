{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenizing_text_creating_sequences_sentences.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF3natL-5FB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhJnpcv-FUMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [\n",
        "    'One of my favorite programming language is Python',\n",
        "    'do you like computer too?',\n",
        "    'My dog likes to play!',\n",
        "    \"My favorite car is Bugatti\",\n",
        "    \"Bugatti was a French car manufacturer of high-performance automobiles\",\n",
        "    \"My car, my machine, and my transport\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV00rRSoF-xa",
        "colab_type": "text"
      },
      "source": [
        "**Tokenize the words**\n",
        "The first step to preparing text to be used in a machine learning model is to tokenize the text, in other words, to generate numbers for the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3rn9bNEF749",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optionally set the max number of words to tokenize.\n",
        "# The out of vocabulary (OOV) token represents words that are not in the index.\n",
        "# Call fit_on_text() on the tokenizer to generate unique numbers for each word\n",
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w33nWpJiGMRc",
        "colab_type": "text"
      },
      "source": [
        "**View the word index**\n",
        "\n",
        "After tokenize the text, the tokenizer has a word index that contains key-value pairs for all the words and their numbers.\n",
        "\n",
        "The word is the key, and the number is the value.\n",
        "\n",
        "Notice that the OOV token is the first entry."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlRHe2aFGF79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "633f4402-6c85-4516-fc49-33fcae7917ba"
      },
      "source": [
        "# Examine the word index\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<OOV>': 1, 'my': 2, 'car': 3, 'of': 4, 'favorite': 5, 'is': 6, 'bugatti': 7, 'one': 8, 'programming': 9, 'language': 10, 'python': 11, 'do': 12, 'you': 13, 'like': 14, 'computer': 15, 'too': 16, 'dog': 17, 'likes': 18, 'to': 19, 'play': 20, 'was': 21, 'a': 22, 'french': 23, 'manufacturer': 24, 'high': 25, 'performance': 26, 'automobiles': 27, 'machine': 28, 'and': 29, 'transport': 30}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nlKLecCGYOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6689dfa0-ea83-44ae-a8e4-f2057e6d2c88"
      },
      "source": [
        "# Get the number for a given word\n",
        "print(word_index['language'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLHWTfHBGpoT",
        "colab_type": "text"
      },
      "source": [
        "**Create sequences for the sentences**\n",
        "\n",
        "After tokenize the words, the word index contains a unique number for each word. However, the numbers in the word index are not ordered. Words in a sentence have an order. So after tokenizing the words, the next step is to generate sequences for the sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rWGz0oSGh2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c447c50-95ac-420b-f07a-f5f08a934a8f"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print (sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8, 4, 2, 5, 9, 10, 6, 11], [12, 13, 14, 15, 16], [2, 17, 18, 19, 20], [2, 5, 3, 6, 7], [7, 21, 22, 23, 3, 24, 4, 25, 26, 27], [2, 3, 2, 28, 29, 2, 30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU7n6fOHG7RV",
        "colab_type": "text"
      },
      "source": [
        "Sequence sentences that contain words that are not in the word index\n",
        "Let's take a look at what happens if the sentence being sequenced contains words that are not in the word index.\n",
        "\n",
        "The Out of Vocabluary (OOV) token is the first entry in the word index. We will see it shows up in the sequences in place of any word that is not in the word index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCoSQqt7Gvr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a05259e0-d2fd-4feb-a2a7-f2d2297b2540"
      },
      "source": [
        "new_sentences = [\"I like sport car\", \"My car and my machine are made by myself but both need improvement\"]\n",
        "\n",
        "sequences2 = tokenizer.texts_to_sequences(new_sentences)\n",
        "print(sequences2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 14, 1, 3], [2, 3, 29, 2, 28, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j15V2zfBJnFV",
        "colab_type": "text"
      },
      "source": [
        "**Make the sequences all the same length**\n",
        "\n",
        "Later, when feed the sequences into a neural network to train a model, the sequences all **need to be uniform in size**. Currently the sequences have varied lengths, so the next step is to make them all be the same size, either by padding them with zeros and/or truncating them.\n",
        "\n",
        "Use `f.keras.preprocessing.sequence.pad_sequences` to add zeros to the sequences to make them all be the same length. By default, the padding goes at the start of the sequences, but we can specify to pad at the end.\n",
        "\n",
        "We can optionally specify the maximum length to pad the sequences to. Sequences that are longer than the specified max length will be truncated. By default, sequences are truncated from the beginning of the sequence, but we can specify to truncate from the end.\n",
        "\n",
        "If the max length is not provided, then the sequences are padded to match the length of the longest sentence.\n",
        "\n",
        "For all the options when padding and truncating sequences, see https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "794NU2m5HVDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "14e5f795-15b0-425e-bfe0-03dae2adf7c6"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded = pad_sequences(sequences)\n",
        "print(\"\\nWord Index = \" , word_index)\n",
        "print(\"\\nSequences = \" , sequences)\n",
        "print(\"\\nPadded Sequences:\")\n",
        "print(padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Word Index =  {'<OOV>': 1, 'my': 2, 'car': 3, 'of': 4, 'favorite': 5, 'is': 6, 'bugatti': 7, 'one': 8, 'programming': 9, 'language': 10, 'python': 11, 'do': 12, 'you': 13, 'like': 14, 'computer': 15, 'too': 16, 'dog': 17, 'likes': 18, 'to': 19, 'play': 20, 'was': 21, 'a': 22, 'french': 23, 'manufacturer': 24, 'high': 25, 'performance': 26, 'automobiles': 27, 'machine': 28, 'and': 29, 'transport': 30}\n",
            "\n",
            "Sequences =  [[8, 4, 2, 5, 9, 10, 6, 11], [12, 13, 14, 15, 16], [2, 17, 18, 19, 20], [2, 5, 3, 6, 7], [7, 21, 22, 23, 3, 24, 4, 25, 26, 27], [2, 3, 2, 28, 29, 2, 30]]\n",
            "\n",
            "Padded Sequences:\n",
            "[[ 0  0  8  4  2  5  9 10  6 11]\n",
            " [ 0  0  0  0  0 12 13 14 15 16]\n",
            " [ 0  0  0  0  0  2 17 18 19 20]\n",
            " [ 0  0  0  0  0  2  5  3  6  7]\n",
            " [ 7 21 22 23  3 24  4 25 26 27]\n",
            " [ 0  0  0  2  3  2 28 29  2 30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9-pdzP8KO2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fd46a6d8-ba16-4dcc-8ccd-f4ba8fefc157"
      },
      "source": [
        "# Specify a max length for the padded sequences\n",
        "padded = pad_sequences(sequences, maxlen=15)\n",
        "print(padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  0  0  0  8  4  2  5  9 10  6 11]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 12 13 14 15 16]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  2 17 18 19 20]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  2  5  3  6  7]\n",
            " [ 0  0  0  0  0  7 21 22 23  3 24  4 25 26 27]\n",
            " [ 0  0  0  0  0  0  0  0  2  3  2 28 29  2 30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYBDHxf_KcsC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2c4007b3-14e4-4f1c-a54b-68c702f28791"
      },
      "source": [
        "# Put the padding at the end of the sequences\n",
        "padded = pad_sequences(sequences, maxlen=15, padding=\"post\")\n",
        "print(padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 8  4  2  5  9 10  6 11  0  0  0  0  0  0  0]\n",
            " [12 13 14 15 16  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2 17 18 19 20  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  5  3  6  7  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 7 21 22 23  3 24  4 25 26 27  0  0  0  0  0]\n",
            " [ 2  3  2 28 29  2 30  0  0  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTW7H0bWKdY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2e07e092-ccaa-4e4c-8b86-8224902f7448"
      },
      "source": [
        "# truncated\n",
        "padded = pad_sequences(sequences, maxlen=3)\n",
        "print(padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10  6 11]\n",
            " [14 15 16]\n",
            " [18 19 20]\n",
            " [ 3  6  7]\n",
            " [25 26 27]\n",
            " [29  2 30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQOpVUA9KwQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "820812ee-2c54-418c-d8b7-0500681280c4"
      },
      "source": [
        "# Try turning sentences that contain words that \n",
        "# aren't in the word index into sequences.\n",
        "test_data = [\n",
        "    \"my best friend's favorite car is Audi and car manufacturer is at French\",\n",
        "    \"my best friend like auto machine\"\n",
        "]\n",
        "print (test_data)\n",
        "\n",
        "# Remind ourselves which number corresponds to the\n",
        "# out of vocabulary token in the word index\n",
        "print(\"<OOV> has the number\", word_index['<OOV>'], \"in the word index.\")\n",
        "\n",
        "# Convert the test sentences to sequences\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "print(\"\\nTest Sequence = \", test_seq)\n",
        "\n",
        "# Pad the new sequences\n",
        "padded = pad_sequences(test_seq)\n",
        "print(\"\\nPadded Test Sequence: \")\n",
        "\n",
        "# Notice that \"1\" appears in the sequence wherever there's a word \n",
        "# that's not in the word index\n",
        "print(padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"my best friend's favorite car is Audi and car manufacturer is at French\", 'my best friend like auto machine']\n",
            "<OOV> has the number 1 in the word index.\n",
            "\n",
            "Test Sequence =  [[2, 1, 1, 5, 3, 6, 1, 29, 3, 24, 6, 1, 23], [2, 1, 1, 14, 1, 28]]\n",
            "\n",
            "Padded Test Sequence: \n",
            "[[ 2  1  1  5  3  6  1 29  3 24  6  1 23]\n",
            " [ 0  0  0  0  0  0  0  2  1  1 14  1 28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHWGrl2ULp4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}